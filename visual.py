import keras
import numpy as np
import cv2
from keras.layers import Conv3D
from keras import backend as K
from typing import List

import os

import data
import gesture
import model
import preproc

class Visualizer:
    """
    A filter visualizer for 3D convolutional networks involved in this project.
    """
    
    def __init__(self, model_name: str):
        """
        Constructor
        :param model_name: name of the model defined in model.py
        """
        self.model: keras.Model = model.load_model(model_name)
        self.name = model_name

    def visualize(self, layer_idx: int, gesture_dir: str, gesture_idx: int, sample_idx: int = 0,
                  save_dir: str = "visual") -> None:
        """
        Visualize all feature maps of a gesture generated by a convolutional layers and save 
        results to disk.
        :param layer_idx: index of the target layer in convolutional layer list
        :param gesture_dir: where all the gesture samples are stored
        :param gesture_idx: index of gesture category specified in gesture.py
        :param sample_idx: index of sample in this gesture category
        :param save_dir: where to save visualization results
        """
        # Pick up the target layer
        conv_layers: List[Conv3D] = []
        for layer in self.model.layers:
            if isinstance(layer, Conv3D):
                conv_layers.append(layer)
        assert layer_idx < len(conv_layers)
        target_layer = conv_layers[layer_idx]
        
        # Build visualization model
        vis_model = keras.models.Model(inputs=self.model.input, outputs=target_layer.output)

        # Pass sample to model
        input_sample = data.load_one_sample(gesture_dir, gesture_idx)
        input_sample = np.expand_dims(preproc.normalize_sample(input_sample), 0)
        output = vis_model.predict(input_sample)[0]

        # Compute output image layout
        num_features = output.shape[3]
        num_cols = min(num_features, 8)
        num_rows = int((num_features - 1) / num_cols) + 1
        feat_size = (120, 90)
        image_size = (feat_size[1] * num_rows, feat_size[0] * num_cols)
        calc_start_pos = lambda idx: (int(idx / num_cols) * feat_size[1], (idx % num_cols) * feat_size[0])

        # Output visualization results
        if not os.path.exists(save_dir):
            os.mkdir(save_dir)
        model_dir = os.path.join(save_dir, self.name)
        if not os.path.exists(model_dir):
            os.mkdir(model_dir)
        gesture_dir = os.path.join(model_dir, gesture.category_names[gesture_idx])
        if not os.path.exists(gesture_dir):
            os.mkdir(gesture_dir)
        for frame_idx in range(output.shape[0]):
            frame_img = np.ndarray(image_size)
            for feature_idx in range(num_features):
                one_feature = cv2.resize(self._to_uint8(output[frame_idx, :, :, feature_idx]), feat_size,
                    interpolation=cv2.INTER_CUBIC)
                start_pos = calc_start_pos(feature_idx)
                frame_img[start_pos[0]:start_pos[0]+feat_size[1], 
                    start_pos[1]:start_pos[1]+feat_size[0]] = one_feature
            img_path = os.path.join(gesture_dir, "l%d_f%d.jpg" % (layer_idx, frame_idx))
            cv2.imwrite(img_path, frame_img)


    @staticmethod
    def _to_uint8(chan: np.ndarray):
        """
        Convert a float channel to a valid uint8 one
        :param chan: input channel
        """
        # Normalize sample
        chan = 0.25 * (chan - chan.mean()) / (chan.std() + K.epsilon())
        # Clip to [0, 1]
        chan = np.clip(chan + 0.5, 0, 1)
        # Convert to uint8
        return np.clip(chan * 255, 0, 255).astype(np.uint8)


if __name__ == "__main__":
    vis = Visualizer("lrn")
    for gesture_idx in range(len(gesture.category_names)):
        for layer_idx in range(4):
            vis.visualize(layer_idx, "train_data", gesture_idx)